asm_test::atomic_memcpy_load_align1::read_volatile_acquire_fence:
        save              %sp, -288, %sp
        ldub              [ %i1 + 0x3f ], %i2
        st                %i2, [ %fp + 0x7fb ]
        ldub              [ %i1 + 0x3e ], %i2
        st                %i2, [ %fp + 0x7f7 ]
        ldub              [ %i1 + 0x3d ], %i2
        st                %i2, [ %fp + 0x7f3 ]
        ldub              [ %i1 + 0x3c ], %i2
        st                %i2, [ %fp + 0x7ef ]
        ldub              [ %i1 + 0x3b ], %i2
        st                %i2, [ %fp + 0x7eb ]
        ldub              [ %i1 + 0x3a ], %i2
        st                %i2, [ %fp + 0x7e7 ]
        ldub              [ %i1 + 0x39 ], %i2
        st                %i2, [ %fp + 0x7e3 ]
        ldub              [ %i1 + 0x38 ], %i2
        st                %i2, [ %fp + 0x7df ]
        ldub              [ %i1 + 0x37 ], %i2
        st                %i2, [ %fp + 0x7db ]
        ldub              [ %i1 + 0x36 ], %i2
        st                %i2, [ %fp + 0x7d7 ]
        ldub              [ %i1 + 0x35 ], %i2
        st                %i2, [ %fp + 0x7d3 ]
        ldub              [ %i1 + 0x34 ], %i2
        st                %i2, [ %fp + 0x7cf ]
        ldub              [ %i1 + 0x33 ], %i2
        st                %i2, [ %fp + 0x7cb ]
        ldub              [ %i1 + 0x32 ], %i2
        st                %i2, [ %fp + 0x7c7 ]
        ldub              [ %i1 + 0x31 ], %i2
        st                %i2, [ %fp + 0x7c3 ]
        ldub              [ %i1 + 0x30 ], %i2
        st                %i2, [ %fp + 0x7bf ]
        ldub              [ %i1 + 0x2f ], %i2
        st                %i2, [ %fp + 0x7bb ]
        ldub              [ %i1 + 0x2e ], %i2
        st                %i2, [ %fp + 0x7b7 ]
        ldub              [ %i1 + 0x2d ], %i2
        st                %i2, [ %fp + 0x7b3 ]
        ldub              [ %i1 + 0x2c ], %i2
        st                %i2, [ %fp + 0x7af ]
        ldub              [ %i1 + 0x2b ], %i2
        st                %i2, [ %fp + 0x7ab ]
        ldub              [ %i1 + 0x2a ], %i2
        st                %i2, [ %fp + 0x7a7 ]
        ldub              [ %i1 + 0x29 ], %i2
        st                %i2, [ %fp + 0x7a3 ]
        ldub              [ %i1 + 0x28 ], %i2
        st                %i2, [ %fp + 0x79f ]
        ldub              [ %i1 + 0x27 ], %i2
        st                %i2, [ %fp + 0x79b ]
        ldub              [ %i1 + 0x26 ], %i2
        st                %i2, [ %fp + 0x797 ]
        ldub              [ %i1 + 0x25 ], %i2
        st                %i2, [ %fp + 0x793 ]
        ldub              [ %i1 + 0x24 ], %i2
        st                %i2, [ %fp + 0x78f ]
        ldub              [ %i1 + 0x23 ], %i2
        st                %i2, [ %fp + 0x78b ]
        ldub              [ %i1 + 0x22 ], %i2
        st                %i2, [ %fp + 0x787 ]
        ldub              [ %i1 + 0x21 ], %i2
        st                %i2, [ %fp + 0x783 ]
        ldub              [ %i1 + 0x20 ], %i2
        st                %i2, [ %fp + 0x77f ]
        ldub              [ %i1 + 0x1f ], %i2
        st                %i2, [ %fp + 0x77b ]
        ldub              [ %i1 + 0x1e ], %i2
        st                %i2, [ %fp + 0x777 ]
        ldub              [ %i1 + 0x1d ], %i2
        st                %i2, [ %fp + 0x773 ]
        ldub              [ %i1 + 0x1c ], %i2
        st                %i2, [ %fp + 0x76f ]
        ldub              [ %i1 + 0x1b ], %i2
        st                %i2, [ %fp + 0x76b ]
        ldub              [ %i1 + 0x1a ], %i2
        st                %i2, [ %fp + 0x767 ]
        ldub              [ %i1 + 0x19 ], %i2
        st                %i2, [ %fp + 0x763 ]
        ldub              [ %i1 + 0x18 ], %i2
        st                %i2, [ %fp + 0x75f ]
        ldub              [ %i1 + 0x17 ], %o7
        ldub              [ %i1 + 0x16 ], %o5
        ldub              [ %i1 + 0x15 ], %o4
        ldub              [ %i1 + 0x14 ], %o3
        ldub              [ %i1 + 0x13 ], %o2
        ldub              [ %i1 + 0x12 ], %o1
        ldub              [ %i1 + 0x11 ], %o0
        ldub              [ %i1 + 0x10 ], %l7
        ldub              [ %i1 + 0xf ], %l6
        ldub              [ %i1 + 0xe ], %l5
        ldub              [ %i1 + 0xd ], %l4
        ldub              [ %i1 + 0xc ], %l3
        ldub              [ %i1 + 0xb ], %l2
        ldub              [ %i1 + 0xa ], %l1
        ldub              [ %i1 + 9 ], %l0
        ldub              [ %i1 + 8 ], %g5
        ldub              [ %i1 + 7 ], %g4
        ldub              [ %i1 + 6 ], %g3
        ldub              [ %i1 + 5 ], %g2
        ldub              [ %i1 + 4 ], %i5
        ldub              [ %i1 + 3 ], %i4
        ldub              [ %i1 + 2 ], %i3
        ldub              [ %i1 + 1 ], %i2
        ldub              [ %i1 ], %i1
        stb               %i1, [ %i0 ]
        stb               %i2, [ %i0 + 1 ]
        stb               %i3, [ %i0 + 2 ]
        stb               %i4, [ %i0 + 3 ]
        stb               %i5, [ %i0 + 4 ]
        stb               %g2, [ %i0 + 5 ]
        stb               %g3, [ %i0 + 6 ]
        stb               %g4, [ %i0 + 7 ]
        stb               %g5, [ %i0 + 8 ]
        stb               %l0, [ %i0 + 9 ]
        stb               %l1, [ %i0 + 0xa ]
        stb               %l2, [ %i0 + 0xb ]
        stb               %l3, [ %i0 + 0xc ]
        stb               %l4, [ %i0 + 0xd ]
        stb               %l5, [ %i0 + 0xe ]
        stb               %l6, [ %i0 + 0xf ]
        stb               %l7, [ %i0 + 0x10 ]
        stb               %o0, [ %i0 + 0x11 ]
        stb               %o1, [ %i0 + 0x12 ]
        stb               %o2, [ %i0 + 0x13 ]
        stb               %o3, [ %i0 + 0x14 ]
        stb               %o4, [ %i0 + 0x15 ]
        stb               %o5, [ %i0 + 0x16 ]
        stb               %o7, [ %i0 + 0x17 ]
        ld                [ %fp + 0x75f ], %i1
        stb               %i1, [ %i0 + 0x18 ]
        ld                [ %fp + 0x763 ], %i1
        stb               %i1, [ %i0 + 0x19 ]
        ld                [ %fp + 0x767 ], %i1
        stb               %i1, [ %i0 + 0x1a ]
        ld                [ %fp + 0x76b ], %i1
        stb               %i1, [ %i0 + 0x1b ]
        ld                [ %fp + 0x76f ], %i1
        stb               %i1, [ %i0 + 0x1c ]
        ld                [ %fp + 0x773 ], %i1
        stb               %i1, [ %i0 + 0x1d ]
        ld                [ %fp + 0x777 ], %i1
        stb               %i1, [ %i0 + 0x1e ]
        ld                [ %fp + 0x77b ], %i1
        stb               %i1, [ %i0 + 0x1f ]
        ld                [ %fp + 0x77f ], %i1
        stb               %i1, [ %i0 + 0x20 ]
        ld                [ %fp + 0x783 ], %i1
        stb               %i1, [ %i0 + 0x21 ]
        ld                [ %fp + 0x787 ], %i1
        stb               %i1, [ %i0 + 0x22 ]
        ld                [ %fp + 0x78b ], %i1
        stb               %i1, [ %i0 + 0x23 ]
        ld                [ %fp + 0x78f ], %i1
        stb               %i1, [ %i0 + 0x24 ]
        ld                [ %fp + 0x793 ], %i1
        stb               %i1, [ %i0 + 0x25 ]
        ld                [ %fp + 0x797 ], %i1
        stb               %i1, [ %i0 + 0x26 ]
        ld                [ %fp + 0x79b ], %i1
        stb               %i1, [ %i0 + 0x27 ]
        ld                [ %fp + 0x79f ], %i1
        stb               %i1, [ %i0 + 0x28 ]
        ld                [ %fp + 0x7a3 ], %i1
        stb               %i1, [ %i0 + 0x29 ]
        ld                [ %fp + 0x7a7 ], %i1
        stb               %i1, [ %i0 + 0x2a ]
        ld                [ %fp + 0x7ab ], %i1
        stb               %i1, [ %i0 + 0x2b ]
        ld                [ %fp + 0x7af ], %i1
        stb               %i1, [ %i0 + 0x2c ]
        ld                [ %fp + 0x7b3 ], %i1
        stb               %i1, [ %i0 + 0x2d ]
        ld                [ %fp + 0x7b7 ], %i1
        stb               %i1, [ %i0 + 0x2e ]
        ld                [ %fp + 0x7bb ], %i1
        stb               %i1, [ %i0 + 0x2f ]
        ld                [ %fp + 0x7bf ], %i1
        stb               %i1, [ %i0 + 0x30 ]
        ld                [ %fp + 0x7c3 ], %i1
        stb               %i1, [ %i0 + 0x31 ]
        ld                [ %fp + 0x7c7 ], %i1
        stb               %i1, [ %i0 + 0x32 ]
        ld                [ %fp + 0x7cb ], %i1
        stb               %i1, [ %i0 + 0x33 ]
        ld                [ %fp + 0x7cf ], %i1
        stb               %i1, [ %i0 + 0x34 ]
        ld                [ %fp + 0x7d3 ], %i1
        stb               %i1, [ %i0 + 0x35 ]
        ld                [ %fp + 0x7d7 ], %i1
        stb               %i1, [ %i0 + 0x36 ]
        ld                [ %fp + 0x7db ], %i1
        stb               %i1, [ %i0 + 0x37 ]
        ld                [ %fp + 0x7df ], %i1
        stb               %i1, [ %i0 + 0x38 ]
        ld                [ %fp + 0x7e3 ], %i1
        stb               %i1, [ %i0 + 0x39 ]
        ld                [ %fp + 0x7e7 ], %i1
        stb               %i1, [ %i0 + 0x3a ]
        ld                [ %fp + 0x7eb ], %i1
        stb               %i1, [ %i0 + 0x3b ]
        ld                [ %fp + 0x7ef ], %i1
        stb               %i1, [ %i0 + 0x3c ]
        ld                [ %fp + 0x7f3 ], %i1
        stb               %i1, [ %i0 + 0x3d ]
        ld                [ %fp + 0x7f7 ], %i1
        stb               %i1, [ %i0 + 0x3e ]
        ld                [ %fp + 0x7fb ], %i1
        stb               %i1, [ %i0 + 0x3f ]
        membar            #LoadStore|#LoadLoad
        ret
        restore

asm_test::atomic_memcpy_load_align1::acquire:
        save              %sp, -240, %sp
        add               %i1, 7, %i2
        and               %i2, -8, %i2
        cmp               %i2, %i1
        bne               %xcc, 0f
        mov               %i0, %o0
        mov               %g0, %i0
        b                 2f
        mov               0x40, %i2
0:
        sub               %i2, %i1, %i0
        add               %fp, 0x7bf, %i3
        sub               %i1, %i2, %i4
        mov               %i1, %i5
1:
        ldub              [ %i5 ], %g2
        mov               %g0, %g3
        stb               %g2, [ %i3 ]
        inc               %i3
        inc               %i4
        movre             %i4, 1, %g3
        btst              1, %g3
        be                %icc, 1b
        inc               %i5
        sub               %i1, %i2, %i2
        add               %i2, 0x40, %i2
        cmp               %i2, 8
        bcs               %xcc, 4f
        nop
2:
        add               %fp, 0x7bf, %i3
3:
        ldx               [ %i1 + %i0 ], %i4
        add               %i3, %i0, %i5
        srlx              %i4, 0x38, %g2
        stb               %g2, [ %i3 + %i0 ]
        stb               %i4, [ %i5 + 7 ]
        srlx              %i4, 8, %g2
        stb               %g2, [ %i5 + 6 ]
        srlx              %i4, 0x10, %g2
        stb               %g2, [ %i5 + 5 ]
        srlx              %i4, 0x18, %g2
        stb               %g2, [ %i5 + 4 ]
        srlx              %i4, 0x20, %g2
        stb               %g2, [ %i5 + 3 ]
        srlx              %i4, 0x28, %g2
        stb               %g2, [ %i5 + 2 ]
        srlx              %i4, 0x30, %i4
        stb               %i4, [ %i5 + 1 ]
        add               %i2, -8, %i2
        cmp               %i2, 7
        bgu               %xcc, 3b
        add               %i0, 8, %i0
4:
        brz               %i2, 6f
        nop
        add               %i1, %i0, %i1
        add               %fp, 0x7bf, %i3
        add               %i3, %i0, %i0
5:
        ldub              [ %i1 ], %i3
        stb               %i3, [ %i0 ]
        inc               %i1
        add               %i2, -1, %i2
        brnz              %i2, 5b
        inc               %i0
6:
        add               %fp, 0x7bf, %o1
7:
        call              7f
        mov               0x40, %o2
        membar            #LoadStore|#LoadLoad
        ret
        restore

asm_test::atomic_memcpy_load_align2::read_volatile_acquire_fence:
        save              %sp, -160, %sp
        lduh              [ %i1 + 0x3e ], %i2
        st                %i2, [ %fp + 0x7fb ]
        lduh              [ %i1 + 0x3c ], %i2
        st                %i2, [ %fp + 0x7f7 ]
        lduh              [ %i1 + 0x3a ], %i2
        st                %i2, [ %fp + 0x7f3 ]
        lduh              [ %i1 + 0x38 ], %i2
        st                %i2, [ %fp + 0x7ef ]
        lduh              [ %i1 + 0x36 ], %i2
        st                %i2, [ %fp + 0x7eb ]
        lduh              [ %i1 + 0x34 ], %i2
        st                %i2, [ %fp + 0x7e7 ]
        lduh              [ %i1 + 0x32 ], %i2
        st                %i2, [ %fp + 0x7e3 ]
        lduh              [ %i1 + 0x30 ], %i2
        st                %i2, [ %fp + 0x7df ]
        lduh              [ %i1 + 0x2e ], %l0
        lduh              [ %i1 + 0x2c ], %l1
        lduh              [ %i1 + 0x2a ], %l2
        lduh              [ %i1 + 0x28 ], %l3
        lduh              [ %i1 + 0x26 ], %l4
        lduh              [ %i1 + 0x24 ], %l5
        lduh              [ %i1 + 0x22 ], %l6
        lduh              [ %i1 + 0x20 ], %l7
        lduh              [ %i1 + 0x1e ], %o0
        lduh              [ %i1 + 0x1c ], %o1
        lduh              [ %i1 + 0x1a ], %o2
        lduh              [ %i1 + 0x18 ], %o3
        lduh              [ %i1 + 0x16 ], %o4
        lduh              [ %i1 + 0x14 ], %o5
        lduh              [ %i1 + 0x12 ], %o7
        lduh              [ %i1 + 0x10 ], %g5
        lduh              [ %i1 + 0xe ], %g4
        lduh              [ %i1 + 0xc ], %g3
        lduh              [ %i1 + 0xa ], %g2
        lduh              [ %i1 + 8 ], %i5
        lduh              [ %i1 + 6 ], %i4
        lduh              [ %i1 + 4 ], %i3
        lduh              [ %i1 + 2 ], %i2
        lduh              [ %i1 ], %i1
        sth               %i1, [ %i0 ]
        sth               %i2, [ %i0 + 2 ]
        sth               %i3, [ %i0 + 4 ]
        sth               %i4, [ %i0 + 6 ]
        sth               %i5, [ %i0 + 8 ]
        sth               %g2, [ %i0 + 0xa ]
        sth               %g3, [ %i0 + 0xc ]
        sth               %g4, [ %i0 + 0xe ]
        sth               %g5, [ %i0 + 0x10 ]
        sth               %o7, [ %i0 + 0x12 ]
        sth               %o5, [ %i0 + 0x14 ]
        sth               %o4, [ %i0 + 0x16 ]
        sth               %o3, [ %i0 + 0x18 ]
        sth               %o2, [ %i0 + 0x1a ]
        sth               %o1, [ %i0 + 0x1c ]
        sth               %o0, [ %i0 + 0x1e ]
        sth               %l7, [ %i0 + 0x20 ]
        sth               %l6, [ %i0 + 0x22 ]
        sth               %l5, [ %i0 + 0x24 ]
        sth               %l4, [ %i0 + 0x26 ]
        sth               %l3, [ %i0 + 0x28 ]
        sth               %l2, [ %i0 + 0x2a ]
        sth               %l1, [ %i0 + 0x2c ]
        sth               %l0, [ %i0 + 0x2e ]
        ld                [ %fp + 0x7df ], %i1
        sth               %i1, [ %i0 + 0x30 ]
        ld                [ %fp + 0x7e3 ], %i1
        sth               %i1, [ %i0 + 0x32 ]
        ld                [ %fp + 0x7e7 ], %i1
        sth               %i1, [ %i0 + 0x34 ]
        ld                [ %fp + 0x7eb ], %i1
        sth               %i1, [ %i0 + 0x36 ]
        ld                [ %fp + 0x7ef ], %i1
        sth               %i1, [ %i0 + 0x38 ]
        ld                [ %fp + 0x7f3 ], %i1
        sth               %i1, [ %i0 + 0x3a ]
        ld                [ %fp + 0x7f7 ], %i1
        sth               %i1, [ %i0 + 0x3c ]
        ld                [ %fp + 0x7fb ], %i1
        sth               %i1, [ %i0 + 0x3e ]
        membar            #LoadStore|#LoadLoad
        ret
        restore

asm_test::atomic_memcpy_load_align2::acquire:
        save              %sp, -240, %sp
        add               %i1, 7, %i2
        and               %i2, -8, %i2
        cmp               %i2, %i1
        bne               %xcc, 0f
        mov               %i0, %o0
        mov               %g0, %i0
        b                 2f
        mov               0x40, %i2
0:
        sub               %i2, %i1, %i0
        add               %fp, 0x7bf, %i3
        sub               %i1, %i2, %i4
        mov               %i1, %i5
1:
        ldub              [ %i5 ], %g2
        mov               %g0, %g3
        stb               %g2, [ %i3 ]
        inc               %i3
        inc               %i4
        movre             %i4, 1, %g3
        btst              1, %g3
        be                %icc, 1b
        inc               %i5
        sub               %i1, %i2, %i2
        add               %i2, 0x40, %i2
        cmp               %i2, 8
        bcs               %xcc, 4f
        nop
2:
        add               %fp, 0x7bf, %i3
3:
        ldx               [ %i1 + %i0 ], %i4
        add               %i3, %i0, %i5
        srlx              %i4, 0x38, %g2
        stb               %g2, [ %i3 + %i0 ]
        stb               %i4, [ %i5 + 7 ]
        srlx              %i4, 8, %g2
        stb               %g2, [ %i5 + 6 ]
        srlx              %i4, 0x10, %g2
        stb               %g2, [ %i5 + 5 ]
        srlx              %i4, 0x18, %g2
        stb               %g2, [ %i5 + 4 ]
        srlx              %i4, 0x20, %g2
        stb               %g2, [ %i5 + 3 ]
        srlx              %i4, 0x28, %g2
        stb               %g2, [ %i5 + 2 ]
        srlx              %i4, 0x30, %i4
        stb               %i4, [ %i5 + 1 ]
        add               %i2, -8, %i2
        cmp               %i2, 7
        bgu               %xcc, 3b
        add               %i0, 8, %i0
4:
        brz               %i2, 6f
        nop
        add               %i1, %i0, %i1
        add               %fp, 0x7bf, %i3
        add               %i3, %i0, %i0
5:
        ldub              [ %i1 ], %i3
        stb               %i3, [ %i0 ]
        inc               %i1
        add               %i2, -1, %i2
        brnz              %i2, 5b
        inc               %i0
6:
        add               %fp, 0x7bf, %o1
7:
        call              7f
        mov               0x40, %o2
        membar            #LoadStore|#LoadLoad
        ret
        restore

asm_test::atomic_memcpy_load_align4::read_volatile_acquire_fence:
        save              %sp, -128, %sp
        ld                [ %i1 + 0x3c ], %i2
        ld                [ %i1 + 0x38 ], %i3
        ld                [ %i1 + 0x34 ], %i4
        ld                [ %i1 + 0x30 ], %i5
        ld                [ %i1 + 0x2c ], %g2
        ld                [ %i1 + 0x28 ], %g3
        ld                [ %i1 + 0x24 ], %g4
        ld                [ %i1 + 0x20 ], %g5
        ld                [ %i1 + 0x1c ], %l0
        ld                [ %i1 + 0x18 ], %l1
        ld                [ %i1 + 0x14 ], %l2
        ld                [ %i1 + 0x10 ], %l3
        ld                [ %i1 + 0xc ], %l4
        ld                [ %i1 + 8 ], %l5
        ld                [ %i1 + 4 ], %l6
        ld                [ %i1 ], %i1
        st                %i1, [ %i0 ]
        st                %l6, [ %i0 + 4 ]
        st                %l5, [ %i0 + 8 ]
        st                %l4, [ %i0 + 0xc ]
        st                %l3, [ %i0 + 0x10 ]
        st                %l2, [ %i0 + 0x14 ]
        st                %l1, [ %i0 + 0x18 ]
        st                %l0, [ %i0 + 0x1c ]
        st                %g5, [ %i0 + 0x20 ]
        st                %g4, [ %i0 + 0x24 ]
        st                %g3, [ %i0 + 0x28 ]
        st                %g2, [ %i0 + 0x2c ]
        st                %i5, [ %i0 + 0x30 ]
        st                %i4, [ %i0 + 0x34 ]
        st                %i3, [ %i0 + 0x38 ]
        st                %i2, [ %i0 + 0x3c ]
        membar            #LoadStore|#LoadLoad
        ret
        restore

asm_test::atomic_memcpy_load_align4::acquire:
        save              %sp, -240, %sp
        add               %i1, 7, %i2
        and               %i2, -8, %i2
        cmp               %i2, %i1
        bne               %xcc, 0f
        mov               %i0, %o0
        mov               %g0, %i0
        b                 2f
        mov               0x40, %i2
0:
        sub               %i2, %i1, %i0
        add               %fp, 0x7bf, %i3
        sub               %i1, %i2, %i4
        mov               %i1, %i5
1:
        ldub              [ %i5 ], %g2
        mov               %g0, %g3
        stb               %g2, [ %i3 ]
        inc               %i3
        inc               %i4
        movre             %i4, 1, %g3
        btst              1, %g3
        be                %icc, 1b
        inc               %i5
        sub               %i1, %i2, %i2
        add               %i2, 0x40, %i2
        cmp               %i2, 8
        bcs               %xcc, 4f
        nop
2:
        add               %fp, 0x7bf, %i3
3:
        ldx               [ %i1 + %i0 ], %i4
        add               %i3, %i0, %i5
        srlx              %i4, 0x38, %g2
        stb               %g2, [ %i3 + %i0 ]
        stb               %i4, [ %i5 + 7 ]
        srlx              %i4, 8, %g2
        stb               %g2, [ %i5 + 6 ]
        srlx              %i4, 0x10, %g2
        stb               %g2, [ %i5 + 5 ]
        srlx              %i4, 0x18, %g2
        stb               %g2, [ %i5 + 4 ]
        srlx              %i4, 0x20, %g2
        stb               %g2, [ %i5 + 3 ]
        srlx              %i4, 0x28, %g2
        stb               %g2, [ %i5 + 2 ]
        srlx              %i4, 0x30, %i4
        stb               %i4, [ %i5 + 1 ]
        add               %i2, -8, %i2
        cmp               %i2, 7
        bgu               %xcc, 3b
        add               %i0, 8, %i0
4:
        brz               %i2, 6f
        nop
        add               %i1, %i0, %i1
        add               %fp, 0x7bf, %i3
        add               %i3, %i0, %i0
5:
        ldub              [ %i1 ], %i3
        stb               %i3, [ %i0 ]
        inc               %i1
        add               %i2, -1, %i2
        brnz              %i2, 5b
        inc               %i0
6:
        add               %fp, 0x7bf, %o1
7:
        call              7f
        mov               0x40, %o2
        membar            #LoadStore|#LoadLoad
        ret
        restore

asm_test::atomic_memcpy_load_align8::read_volatile_acquire_fence:
        ldx               [ %o1 + 0x38 ], %o2
        ldx               [ %o1 + 0x30 ], %o3
        ldx               [ %o1 + 0x28 ], %o4
        ldx               [ %o1 + 0x20 ], %o5
        ldx               [ %o1 + 0x18 ], %g2
        ldx               [ %o1 + 0x10 ], %g3
        ldx               [ %o1 + 8 ], %g4
        ldx               [ %o1 ], %o1
        stx               %o1, [ %o0 ]
        stx               %g4, [ %o0 + 8 ]
        stx               %g3, [ %o0 + 0x10 ]
        stx               %g2, [ %o0 + 0x18 ]
        stx               %o5, [ %o0 + 0x20 ]
        stx               %o4, [ %o0 + 0x28 ]
        stx               %o3, [ %o0 + 0x30 ]
        stx               %o2, [ %o0 + 0x38 ]
        membar            #LoadStore|#LoadLoad
        retl
        nop

asm_test::atomic_memcpy_load_align8::acquire:
        ldx               [ %o1 ], %o2
        ldx               [ %o1 + 8 ], %o3
        ldx               [ %o1 + 0x10 ], %o4
        ldx               [ %o1 + 0x18 ], %o5
        ldx               [ %o1 + 0x20 ], %g2
        ldx               [ %o1 + 0x28 ], %g3
        ldx               [ %o1 + 0x30 ], %g4
        ldx               [ %o1 + 0x38 ], %o1
        stx               %o2, [ %o0 ]
        stx               %o3, [ %o0 + 8 ]
        stx               %o4, [ %o0 + 0x10 ]
        stx               %o5, [ %o0 + 0x18 ]
        stx               %g2, [ %o0 + 0x20 ]
        stx               %g3, [ %o0 + 0x28 ]
        stx               %g4, [ %o0 + 0x30 ]
        stx               %o1, [ %o0 + 0x38 ]
        membar            #LoadStore|#LoadLoad
        retl
        nop

asm_test::atomic_memcpy_load_align16::read_volatile_acquire_fence:
        ldx               [ %o1 + 0x38 ], %o2
        ldx               [ %o1 + 0x30 ], %o3
        ldx               [ %o1 + 0x28 ], %o4
        ldx               [ %o1 + 0x20 ], %o5
        ldx               [ %o1 + 0x18 ], %g2
        ldx               [ %o1 + 0x10 ], %g3
        ldx               [ %o1 + 8 ], %g4
        ldx               [ %o1 ], %o1
        stx               %o1, [ %o0 ]
        stx               %g4, [ %o0 + 8 ]
        stx               %g3, [ %o0 + 0x10 ]
        stx               %g2, [ %o0 + 0x18 ]
        stx               %o5, [ %o0 + 0x20 ]
        stx               %o4, [ %o0 + 0x28 ]
        stx               %o3, [ %o0 + 0x30 ]
        stx               %o2, [ %o0 + 0x38 ]
        membar            #LoadStore|#LoadLoad
        retl
        nop

asm_test::atomic_memcpy_load_align16::acquire:
        ldx               [ %o1 ], %o2
        ldx               [ %o1 + 8 ], %o3
        ldx               [ %o1 + 0x10 ], %o4
        ldx               [ %o1 + 0x18 ], %o5
        ldx               [ %o1 + 0x20 ], %g2
        ldx               [ %o1 + 0x28 ], %g3
        ldx               [ %o1 + 0x30 ], %g4
        ldx               [ %o1 + 0x38 ], %o1
        stx               %o2, [ %o0 ]
        stx               %o3, [ %o0 + 8 ]
        stx               %o4, [ %o0 + 0x10 ]
        stx               %o5, [ %o0 + 0x18 ]
        stx               %g2, [ %o0 + 0x20 ]
        stx               %g3, [ %o0 + 0x28 ]
        stx               %g4, [ %o0 + 0x30 ]
        stx               %o1, [ %o0 + 0x38 ]
        membar            #LoadStore|#LoadLoad
        retl
        nop

asm_test::atomic_memcpy_store_align1::write_volatile_release_fence:
        mov               0x40, %o2
        membar            #StoreStore|#LoadStore
        mov               %o7, %g1
0:
        call              0f
        mov               %g1, %o7

asm_test::atomic_memcpy_store_align1::release:
        add               %o0, 7, %o2
        and               %o2, -8, %o3
        cmp               %o3, %o0
        membar            #StoreStore|#LoadStore
        bne               %xcc, 0f
        nop
        mov               %g0, %o2
        b                 2f
        mov               0x40, %o3
0:
        sub               %o3, %o0, %o2
        sub               %o0, %o3, %o4
        mov               %o1, %o5
        mov               %o0, %g2
1:
        ldub              [ %o5 ], %g3
        mov               %g0, %g4
        stb               %g3, [ %g2 ]
        inc               %g2
        inc               %o4
        movre             %o4, 1, %g4
        btst              1, %g4
        be                %icc, 1b
        inc               %o5
        sub               %o0, %o3, %o3
        add               %o3, 0x40, %o3
        cmp               %o3, 8
        bcs               %xcc, 3f
        nop
2:
        add               %o1, %o2, %o4
        ldub              [ %o4 + 6 ], %o5
        ldub              [ %o4 + 7 ], %g2
        ldub              [ %o4 + 5 ], %g3
        ldub              [ %o4 + 4 ], %g4
        sllx              %o5, 8, %o5
        or                %o5, %g2, %o5
        sllx              %g3, 0x10, %g2
        sllx              %g4, 0x18, %g3
        or                %g3, %g2, %g2
        or                %g2, %o5, %o5
        ldub              [ %o4 + 2 ], %g2
        ldub              [ %o4 + 3 ], %g3
        ldub              [ %o1 + %o2 ], %g4
        ldub              [ %o4 + 1 ], %o4
        sllx              %g2, 8, %g2
        or                %g2, %g3, %g2
        sllx              %g4, 0x18, %g3
        sllx              %o4, 0x10, %o4
        or                %g3, %o4, %o4
        or                %o4, %g2, %o4
        sllx              %o4, 0x20, %o4
        or                %o4, %o5, %o4
        stx               %o4, [ %o0 + %o2 ]
        add               %o3, -8, %o3
        cmp               %o3, 7
        bgu               %xcc, 2b
        add               %o2, 8, %o2
3:
        brz               %o3, 5f
        nop
        add               %o1, %o2, %o1
        add               %o0, %o2, %o0
4:
        ldub              [ %o1 ], %o2
        stb               %o2, [ %o0 ]
        inc               %o1
        add               %o3, -1, %o3
        brnz              %o3, 4b
        inc               %o0
5:
        retl
        nop

asm_test::atomic_memcpy_store_align2::write_volatile_release_fence:
        mov               0x40, %o2
        membar            #StoreStore|#LoadStore
        mov               %o7, %g1
0:
        call              0f
        mov               %g1, %o7

asm_test::atomic_memcpy_store_align2::release:
        add               %o0, 7, %o2
        and               %o2, -8, %o3
        cmp               %o3, %o0
        membar            #StoreStore|#LoadStore
        bne               %xcc, 0f
        nop
        mov               %g0, %o2
        b                 2f
        mov               0x40, %o3
0:
        sub               %o3, %o0, %o2
        sub               %o0, %o3, %o4
        mov               %o1, %o5
        mov               %o0, %g2
1:
        ldub              [ %o5 ], %g3
        mov               %g0, %g4
        stb               %g3, [ %g2 ]
        inc               %g2
        inc               %o4
        movre             %o4, 1, %g4
        btst              1, %g4
        be                %icc, 1b
        inc               %o5
        sub               %o0, %o3, %o3
        add               %o3, 0x40, %o3
        cmp               %o3, 8
        bcs               %xcc, 3f
        nop
2:
        add               %o1, %o2, %o4
        ldub              [ %o4 + 6 ], %o5
        ldub              [ %o4 + 7 ], %g2
        ldub              [ %o4 + 5 ], %g3
        ldub              [ %o4 + 4 ], %g4
        sllx              %o5, 8, %o5
        or                %o5, %g2, %o5
        sllx              %g3, 0x10, %g2
        sllx              %g4, 0x18, %g3
        or                %g3, %g2, %g2
        or                %g2, %o5, %o5
        ldub              [ %o4 + 2 ], %g2
        ldub              [ %o4 + 3 ], %g3
        ldub              [ %o1 + %o2 ], %g4
        ldub              [ %o4 + 1 ], %o4
        sllx              %g2, 8, %g2
        or                %g2, %g3, %g2
        sllx              %g4, 0x18, %g3
        sllx              %o4, 0x10, %o4
        or                %g3, %o4, %o4
        or                %o4, %g2, %o4
        sllx              %o4, 0x20, %o4
        or                %o4, %o5, %o4
        stx               %o4, [ %o0 + %o2 ]
        add               %o3, -8, %o3
        cmp               %o3, 7
        bgu               %xcc, 2b
        add               %o2, 8, %o2
3:
        brz               %o3, 5f
        nop
        add               %o1, %o2, %o1
        add               %o0, %o2, %o0
4:
        ldub              [ %o1 ], %o2
        stb               %o2, [ %o0 ]
        inc               %o1
        add               %o3, -1, %o3
        brnz              %o3, 4b
        inc               %o0
5:
        retl
        nop

asm_test::atomic_memcpy_store_align4::write_volatile_release_fence:
        mov               0x40, %o2
        membar            #StoreStore|#LoadStore
        mov               %o7, %g1
0:
        call              0f
        mov               %g1, %o7

asm_test::atomic_memcpy_store_align4::release:
        add               %o0, 7, %o2
        and               %o2, -8, %o3
        cmp               %o3, %o0
        membar            #StoreStore|#LoadStore
        bne               %xcc, 0f
        nop
        mov               %g0, %o2
        b                 2f
        mov               0x40, %o3
0:
        sub               %o3, %o0, %o2
        sub               %o0, %o3, %o4
        mov               %o1, %o5
        mov               %o0, %g2
1:
        ldub              [ %o5 ], %g3
        mov               %g0, %g4
        stb               %g3, [ %g2 ]
        inc               %g2
        inc               %o4
        movre             %o4, 1, %g4
        btst              1, %g4
        be                %icc, 1b
        inc               %o5
        sub               %o0, %o3, %o3
        add               %o3, 0x40, %o3
        cmp               %o3, 8
        bcs               %xcc, 3f
        nop
2:
        add               %o1, %o2, %o4
        ldub              [ %o4 + 6 ], %o5
        ldub              [ %o4 + 7 ], %g2
        ldub              [ %o4 + 5 ], %g3
        ldub              [ %o4 + 4 ], %g4
        sllx              %o5, 8, %o5
        or                %o5, %g2, %o5
        sllx              %g3, 0x10, %g2
        sllx              %g4, 0x18, %g3
        or                %g3, %g2, %g2
        or                %g2, %o5, %o5
        ldub              [ %o4 + 2 ], %g2
        ldub              [ %o4 + 3 ], %g3
        ldub              [ %o1 + %o2 ], %g4
        ldub              [ %o4 + 1 ], %o4
        sllx              %g2, 8, %g2
        or                %g2, %g3, %g2
        sllx              %g4, 0x18, %g3
        sllx              %o4, 0x10, %o4
        or                %g3, %o4, %o4
        or                %o4, %g2, %o4
        sllx              %o4, 0x20, %o4
        or                %o4, %o5, %o4
        stx               %o4, [ %o0 + %o2 ]
        add               %o3, -8, %o3
        cmp               %o3, 7
        bgu               %xcc, 2b
        add               %o2, 8, %o2
3:
        brz               %o3, 5f
        nop
        add               %o1, %o2, %o1
        add               %o0, %o2, %o0
4:
        ldub              [ %o1 ], %o2
        stb               %o2, [ %o0 ]
        inc               %o1
        add               %o3, -1, %o3
        brnz              %o3, 4b
        inc               %o0
5:
        retl
        nop

asm_test::atomic_memcpy_store_align8::write_volatile_release_fence:
        membar            #StoreStore|#LoadStore
        ldx               [ %o1 + 0x38 ], %o2
        stx               %o2, [ %o0 + 0x38 ]
        ldx               [ %o1 + 0x30 ], %o2
        stx               %o2, [ %o0 + 0x30 ]
        ldx               [ %o1 + 0x28 ], %o2
        stx               %o2, [ %o0 + 0x28 ]
        ldx               [ %o1 + 0x20 ], %o2
        stx               %o2, [ %o0 + 0x20 ]
        ldx               [ %o1 + 0x18 ], %o2
        stx               %o2, [ %o0 + 0x18 ]
        ldx               [ %o1 + 0x10 ], %o2
        stx               %o2, [ %o0 + 0x10 ]
        ldx               [ %o1 + 8 ], %o2
        stx               %o2, [ %o0 + 8 ]
        ldx               [ %o1 ], %o1
        retl
        stx               %o1, [ %o0 ]

asm_test::atomic_memcpy_store_align8::release:
        membar            #StoreStore|#LoadStore
        ldx               [ %o1 ], %o2
        stx               %o2, [ %o0 ]
        ldx               [ %o1 + 8 ], %o2
        stx               %o2, [ %o0 + 8 ]
        ldx               [ %o1 + 0x10 ], %o2
        stx               %o2, [ %o0 + 0x10 ]
        ldx               [ %o1 + 0x18 ], %o2
        stx               %o2, [ %o0 + 0x18 ]
        ldx               [ %o1 + 0x20 ], %o2
        stx               %o2, [ %o0 + 0x20 ]
        ldx               [ %o1 + 0x28 ], %o2
        stx               %o2, [ %o0 + 0x28 ]
        ldx               [ %o1 + 0x30 ], %o2
        stx               %o2, [ %o0 + 0x30 ]
        ldx               [ %o1 + 0x38 ], %o1
        retl
        stx               %o1, [ %o0 + 0x38 ]

asm_test::atomic_memcpy_store_align16::write_volatile_release_fence:
        membar            #StoreStore|#LoadStore
        ldx               [ %o1 + 0x38 ], %o2
        stx               %o2, [ %o0 + 0x38 ]
        ldx               [ %o1 + 0x30 ], %o2
        stx               %o2, [ %o0 + 0x30 ]
        ldx               [ %o1 + 0x28 ], %o2
        stx               %o2, [ %o0 + 0x28 ]
        ldx               [ %o1 + 0x20 ], %o2
        stx               %o2, [ %o0 + 0x20 ]
        ldx               [ %o1 + 0x18 ], %o2
        stx               %o2, [ %o0 + 0x18 ]
        ldx               [ %o1 + 0x10 ], %o2
        stx               %o2, [ %o0 + 0x10 ]
        ldx               [ %o1 + 8 ], %o2
        stx               %o2, [ %o0 + 8 ]
        ldx               [ %o1 ], %o1
        retl
        stx               %o1, [ %o0 ]

asm_test::atomic_memcpy_store_align16::release:
        membar            #StoreStore|#LoadStore
        ldx               [ %o1 ], %o2
        stx               %o2, [ %o0 ]
        ldx               [ %o1 + 8 ], %o2
        stx               %o2, [ %o0 + 8 ]
        ldx               [ %o1 + 0x10 ], %o2
        stx               %o2, [ %o0 + 0x10 ]
        ldx               [ %o1 + 0x18 ], %o2
        stx               %o2, [ %o0 + 0x18 ]
        ldx               [ %o1 + 0x20 ], %o2
        stx               %o2, [ %o0 + 0x20 ]
        ldx               [ %o1 + 0x28 ], %o2
        stx               %o2, [ %o0 + 0x28 ]
        ldx               [ %o1 + 0x30 ], %o2
        stx               %o2, [ %o0 + 0x30 ]
        ldx               [ %o1 + 0x38 ], %o1
        retl
        stx               %o1, [ %o0 + 0x38 ]
