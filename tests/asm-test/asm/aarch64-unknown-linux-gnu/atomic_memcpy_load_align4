asm_test::atomic_memcpy_load_align4::acquire:
 sub     sp, sp, #64
 add     x9, x0, #7
 and     x10, x9, #0xfffffffffffffff8
 sub     x9, x10, x0
 cmp     x9, #65
 b.lo    .LBB8_2
 ldr     w10, [x0, #60]
 ldr     w9, [x0, #56]
 stp     w9, w10, [sp, #56]
 ldr     w10, [x0, #52]
 ldr     w9, [x0, #48]
 stp     w9, w10, [sp, #48]
 ldr     w10, [x0, #44]
 ldr     w9, [x0, #40]
 stp     w9, w10, [sp, #40]
 ldr     w10, [x0, #36]
 ldr     w9, [x0, #32]
 stp     w9, w10, [sp, #32]
 ldr     w10, [x0, #28]
 ldr     w9, [x0, #24]
 stp     w9, w10, [sp, #24]
 ldr     w10, [x0, #20]
 ldr     w9, [x0, #16]
 stp     w9, w10, [sp, #16]
 ldr     w10, [x0, #12]
 ldr     w9, [x0, #8]
 stp     w9, w10, [sp, #8]
 ldr     w10, [x0, #4]
 ldr     w9, [x0]
 stp     w9, w10, [sp]
 b       .LBB8_12
.LBB8_2:
 cbz     x9, .LBB8_6
 sub     x10, x0, x10
 mov     x11, sp
 mov     x12, x10
 mov     x13, x0
.LBB8_4:
 ldrb    w14, [x13], #1
 adds    x12, x12, #1
 strb    w14, [x11], #1
 b.lo    .LBB8_4
 add     x10, x10, #64
 cmp     x10, #8
 b.hs    .LBB8_7
 b       .LBB8_9
.LBB8_6:
 mov     w10, #64
.LBB8_7:
 mov     x11, sp
.LBB8_8:
 ldr     x12, [x0, x9]
 sub     x10, x10, #8
 cmp     x10, #7
 str     x12, [x11, x9]
 add     x9, x9, #8
 b.hi    .LBB8_8
.LBB8_9:
 cbz     x10, .LBB8_12
 mov     x11, sp
 add     x11, x11, x9
 add     x9, x0, x9
.LBB8_11:
 ldrb    w12, [x9], #1
 subs    x10, x10, #1
 strb    w12, [x11], #1
 b.ne    .LBB8_11
.LBB8_12:
 ldp     q0, q1, [sp]
 ldp     q2, q3, [sp, #32]
 stp     q0, q1, [x8]
 stp     q2, q3, [x8, #32]
 dmb     ishld
 add     sp, sp, #64
 ret
asm_test::atomic_memcpy_load_align4::read_volatile_acquire_fence:
 ldr     w9, [x0, #60]
 ldr     w10, [x0, #56]
 ldr     w11, [x0, #52]
 ldr     w12, [x0, #48]
 ldr     w13, [x0, #44]
 ldr     w14, [x0, #40]
 ldr     w15, [x0, #36]
 ldr     w16, [x0, #32]
 ldr     w17, [x0, #28]
 ldr     w18, [x0, #24]
 ldr     w1, [x0, #20]
 ldr     w2, [x0, #16]
 ldr     w3, [x0, #12]
 ldr     w4, [x0, #8]
 ldr     w5, [x0, #4]
 ldr     w0, [x0]
 stp     w2, w1, [x8, #16]
 stp     w4, w3, [x8, #8]
 stp     w18, w17, [x8, #24]
 stp     w0, w5, [x8]
 stp     w16, w15, [x8, #32]
 stp     w14, w13, [x8, #40]
 stp     w12, w11, [x8, #48]
 stp     w10, w9, [x8, #56]
 dmb     ishld
 ret
