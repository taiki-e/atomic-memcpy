asm_test::atomic_memcpy_store_align2::release:
 addi    sp, sp, -128
 lhu     a2, 58(a1)
 lhu     a3, 56(a1)
 lhu     a4, 62(a1)
 lhu     a5, 60(a1)
 slli    a2, a2, 16
 or      a2, a2, a3
 slli    a3, a4, 16
 or      a3, a3, a5
 slli    a3, a3, 32
 or      a2, a2, a3
 sd      a2, 56(sp)
 lhu     a2, 50(a1)
 lhu     a3, 48(a1)
 lhu     a4, 54(a1)
 lhu     a5, 52(a1)
 slli    a2, a2, 16
 or      a2, a2, a3
 slli    a3, a4, 16
 or      a3, a3, a5
 slli    a3, a3, 32
 or      a2, a2, a3
 sd      a2, 48(sp)
 lhu     a2, 42(a1)
 lhu     a3, 40(a1)
 lhu     a4, 46(a1)
 lhu     a5, 44(a1)
 slli    a2, a2, 16
 or      a2, a2, a3
 slli    a3, a4, 16
 or      a3, a3, a5
 slli    a3, a3, 32
 or      a2, a2, a3
 sd      a2, 40(sp)
 lhu     a2, 34(a1)
 lhu     a3, 32(a1)
 lhu     a4, 38(a1)
 lhu     a5, 36(a1)
 slli    a2, a2, 16
 or      a2, a2, a3
 slli    a3, a4, 16
 or      a3, a3, a5
 slli    a3, a3, 32
 or      a2, a2, a3
 sd      a2, 32(sp)
 lhu     a2, 26(a1)
 lhu     a3, 24(a1)
 lhu     a4, 30(a1)
 lhu     a5, 28(a1)
 slli    a2, a2, 16
 or      a2, a2, a3
 slli    a3, a4, 16
 or      a3, a3, a5
 slli    a3, a3, 32
 or      a2, a2, a3
 sd      a2, 24(sp)
 lhu     a2, 18(a1)
 lhu     a3, 16(a1)
 lhu     a4, 22(a1)
 lhu     a5, 20(a1)
 slli    a2, a2, 16
 or      a2, a2, a3
 slli    a3, a4, 16
 or      a3, a3, a5
 slli    a3, a3, 32
 or      a2, a2, a3
 sd      a2, 16(sp)
 lhu     a2, 10(a1)
 lhu     a3, 8(a1)
 lhu     a4, 14(a1)
 lhu     a5, 12(a1)
 slli    a2, a2, 16
 or      a2, a2, a3
 slli    a3, a4, 16
 or      a3, a3, a5
 slli    a3, a3, 32
 or      a2, a2, a3
 sd      a2, 8(sp)
 lhu     a2, 2(a1)
 lhu     a3, 0(a1)
 lhu     a4, 6(a1)
 lhu     a1, 4(a1)
 slli    a2, a2, 16
 or      a2, a2, a3
 slli    a3, a4, 16
 or      a1, a1, a3
 slli    a1, a1, 32
 or      a1, a1, a2
 sd      a1, 0(sp)
 fence   rw, w
 ld      a1, 56(sp)
 ld      a2, 48(sp)
 ld      a3, 40(sp)
 sd      a1, 120(sp)
 sd      a2, 112(sp)
 sd      a3, 104(sp)
 ld      a1, 32(sp)
 ld      a2, 24(sp)
 ld      a3, 16(sp)
 ld      a4, 8(sp)
 sd      a1, 96(sp)
 sd      a2, 88(sp)
 sd      a3, 80(sp)
 sd      a4, 72(sp)
 ld      a4, 0(sp)
 addi    a1, a0, 7
 andi    a6, a1, -8
 sub     t2, a6, a0
 li      a2, 64
 sd      a4, 64(sp)
 bgeu    a2, t2, .LBB6_2
 lh      a1, 126(sp)
 sh      a1, 62(a0)
 lh      a1, 124(sp)
 sh      a1, 60(a0)
 lh      a1, 122(sp)
 sh      a1, 58(a0)
 lh      a1, 120(sp)
 sh      a1, 56(a0)
 lh      a1, 118(sp)
 sh      a1, 54(a0)
 lh      a1, 116(sp)
 sh      a1, 52(a0)
 lh      a1, 114(sp)
 sh      a1, 50(a0)
 lh      a1, 112(sp)
 sh      a1, 48(a0)
 lh      a1, 110(sp)
 sh      a1, 46(a0)
 lh      a1, 108(sp)
 sh      a1, 44(a0)
 lh      a1, 106(sp)
 sh      a1, 42(a0)
 lh      a1, 104(sp)
 sh      a1, 40(a0)
 lh      a1, 102(sp)
 sh      a1, 38(a0)
 lh      a1, 100(sp)
 sh      a1, 36(a0)
 lh      a1, 98(sp)
 sh      a1, 34(a0)
 lh      a1, 96(sp)
 sh      a1, 32(a0)
 lh      a1, 94(sp)
 sh      a1, 30(a0)
 lh      a1, 92(sp)
 sh      a1, 28(a0)
 lh      a1, 90(sp)
 sh      a1, 26(a0)
 lh      a1, 88(sp)
 sh      a1, 24(a0)
 lh      a1, 86(sp)
 sh      a1, 22(a0)
 lh      a1, 84(sp)
 sh      a1, 20(a0)
 lh      a1, 82(sp)
 sh      a1, 18(a0)
 lh      a1, 80(sp)
 sh      a1, 16(a0)
 lh      a1, 78(sp)
 sh      a1, 14(a0)
 lh      a1, 76(sp)
 sh      a1, 12(a0)
 lh      a1, 74(sp)
 sh      a1, 10(a0)
 lh      a1, 72(sp)
 sh      a1, 8(a0)
 lh      a1, 70(sp)
 sh      a1, 6(a0)
 lh      a1, 68(sp)
 sh      a1, 4(a0)
 lh      a1, 66(sp)
 sh      a1, 2(a0)
 lh      a1, 64(sp)
 sh      a1, 0(a0)
 j       .LBB6_11
.LBB6_2:
 beqz    t2, .LBB6_6
 sub     a4, a0, a6
 addi    a2, sp, 64
 mv      a5, a0
.LBB6_4:
 lb      a7, 0(a2)
 mv      a3, a4
 sb      a7, 0(a5)
 addi    a5, a5, 1
 addi    a4, a4, 1
 addi    a2, a2, 1
 bgeu    a4, a3, .LBB6_4
 sub     a2, a0, a6
 addi    a2, a2, 64
 li      a3, 8
 bltu    a2, a3, .LBB6_8
.LBB6_6:
 addi    a6, sp, 64
 li      a7, 7
.LBB6_7:
 add     a5, a6, t2
 lbu     t0, 1(a5)
 lbu     t1, 0(a5)
 lbu     a3, 3(a5)
 lbu     a4, 2(a5)
 slli    a1, t0, 8
 or      a1, a1, t1
 slli    a3, a3, 8
 or      a3, a3, a4
 slli    a3, a3, 16
 or      t0, a3, a1
 lbu     a3, 5(a5)
 lbu     a4, 4(a5)
 lbu     a1, 7(a5)
 lbu     a5, 6(a5)
 slli    a3, a3, 8
 or      a3, a3, a4
 slli    a1, a1, 8
 or      a1, a1, a5
 slli    a1, a1, 16
 or      a1, a1, a3
 slli    a1, a1, 32
 or      a1, a1, t0
 add     a3, a0, t2
 sd      a1, 0(a3)
 addi    a2, a2, -8
 addi    t2, t2, 8
 bltu    a7, a2, .LBB6_7
.LBB6_8:
 beqz    a2, .LBB6_11
 add     a0, a0, t2
 addi    a1, sp, 64
 add     a1, a1, t2
.LBB6_10:
 lb      a3, 0(a1)
 sb      a3, 0(a0)
 addi    a0, a0, 1
 addi    a2, a2, -1
 addi    a1, a1, 1
 bnez    a2, .LBB6_10
.LBB6_11:
 addi    sp, sp, 128
 ret
asm_test::atomic_memcpy_store_align2::write_volatile_release_fence:
 addi    sp, sp, -80
 sd      ra, 72(sp)
 fence   rw, w
 lhu     a2, 58(a1)
 lhu     a3, 56(a1)
 lhu     a4, 62(a1)
 lhu     a5, 60(a1)
 slli    a2, a2, 16
 or      a2, a2, a3
 slli    a3, a4, 16
 or      a3, a3, a5
 slli    a3, a3, 32
 or      a2, a2, a3
 sd      a2, 64(sp)
 lhu     a2, 50(a1)
 lhu     a3, 48(a1)
 lhu     a4, 54(a1)
 lhu     a5, 52(a1)
 slli    a2, a2, 16
 or      a2, a2, a3
 slli    a3, a4, 16
 or      a3, a3, a5
 slli    a3, a3, 32
 or      a2, a2, a3
 sd      a2, 56(sp)
 lhu     a2, 42(a1)
 lhu     a3, 40(a1)
 lhu     a4, 46(a1)
 lhu     a5, 44(a1)
 slli    a2, a2, 16
 or      a2, a2, a3
 slli    a3, a4, 16
 or      a3, a3, a5
 slli    a3, a3, 32
 or      a2, a2, a3
 sd      a2, 48(sp)
 lhu     a2, 34(a1)
 lhu     a3, 32(a1)
 lhu     a4, 38(a1)
 lhu     a5, 36(a1)
 slli    a2, a2, 16
 or      a2, a2, a3
 slli    a3, a4, 16
 or      a3, a3, a5
 slli    a3, a3, 32
 or      a2, a2, a3
 sd      a2, 40(sp)
 lhu     a2, 26(a1)
 lhu     a3, 24(a1)
 lhu     a4, 30(a1)
 lhu     a5, 28(a1)
 slli    a2, a2, 16
 or      a2, a2, a3
 slli    a3, a4, 16
 or      a3, a3, a5
 slli    a3, a3, 32
 or      a2, a2, a3
 sd      a2, 32(sp)
 lhu     a2, 18(a1)
 lhu     a3, 16(a1)
 lhu     a4, 22(a1)
 lhu     a5, 20(a1)
 slli    a2, a2, 16
 or      a2, a2, a3
 slli    a3, a4, 16
 or      a3, a3, a5
 slli    a3, a3, 32
 or      a2, a2, a3
 sd      a2, 24(sp)
 lhu     a2, 10(a1)
 lhu     a3, 8(a1)
 lhu     a4, 14(a1)
 lhu     a5, 12(a1)
 slli    a2, a2, 16
 or      a2, a2, a3
 slli    a3, a4, 16
 or      a3, a3, a5
 slli    a3, a3, 32
 or      a2, a2, a3
 sd      a2, 16(sp)
 lhu     a2, 2(a1)
 lhu     a3, 0(a1)
 lhu     a4, 6(a1)
 lhu     a1, 4(a1)
 slli    a2, a2, 16
 or      a2, a2, a3
 slli    a3, a4, 16
 or      a1, a1, a3
 slli    a1, a1, 32
 or      a1, a1, a2
 sd      a1, 8(sp)
 addi    a1, sp, 8
 li      a2, 64
 call    memcpy@plt
 ld      ra, 72(sp)
 addi    sp, sp, 80
 ret
