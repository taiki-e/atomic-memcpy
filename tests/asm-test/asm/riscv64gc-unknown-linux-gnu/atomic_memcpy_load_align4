asm_test::atomic_memcpy_load_align4::acquire:
 addi    sp, sp, -80
 sd      ra, 72(sp)
 addi    a2, a1, 7
 andi    a3, a2, -8
 sub     a6, a3, a1
 li      a4, 65
 bgeu    a6, a4, .LBB8_3
 bne     a3, a1, .LBB8_4
 li      a6, 0
 li      a3, 64
 j       .LBB8_9
.LBB8_3:
 lw      a2, 60(a1)
 sw      a2, 68(sp)
 lw      a2, 56(a1)
 sw      a2, 64(sp)
 lw      a2, 52(a1)
 sw      a2, 60(sp)
 lw      a2, 48(a1)
 sw      a2, 56(sp)
 lw      a2, 44(a1)
 sw      a2, 52(sp)
 lw      a2, 40(a1)
 sw      a2, 48(sp)
 lw      a2, 36(a1)
 sw      a2, 44(sp)
 lw      a2, 32(a1)
 sw      a2, 40(sp)
 lw      a2, 28(a1)
 sw      a2, 36(sp)
 lw      a2, 24(a1)
 sw      a2, 32(sp)
 lw      a2, 20(a1)
 sw      a2, 28(sp)
 lw      a2, 16(a1)
 sw      a2, 24(sp)
 lw      a2, 12(a1)
 sw      a2, 20(sp)
 lw      a2, 8(a1)
 sw      a2, 16(sp)
 lw      a2, 4(a1)
 sw      a2, 12(sp)
 lw      a1, 0(a1)
 sw      a1, 8(sp)
 j       .LBB8_14
.LBB8_4:
 li      a3, 1
 bltu    a3, a6, .LBB8_6
 li      a6, 1
.LBB8_6:
 addi    a3, sp, 8
 mv      a4, a6
 mv      a5, a1
.LBB8_7:
 lb      a2, 0(a5)
 sb      a2, 0(a3)
 addi    a3, a3, 1
 addi    a4, a4, -1
 addi    a5, a5, 1
 bnez    a4, .LBB8_7
 li      a3, 64
 sub     a3, a3, a6
 li      a4, 8
 bltu    a3, a4, .LBB8_11
.LBB8_9:
 addi    a7, sp, 8
 li      t0, 7
.LBB8_10:
 add     a2, a1, a6
 ld      a2, 0(a2)
 add     a4, a7, a6
 sb      a2, 0(a4)
 srli    a5, a2, 56
 sb      a5, 7(a4)
 srli    a5, a2, 48
 sb      a5, 6(a4)
 srli    a5, a2, 40
 sb      a5, 5(a4)
 srli    a5, a2, 32
 sb      a5, 4(a4)
 srli    a5, a2, 24
 sb      a5, 3(a4)
 srli    a5, a2, 16
 sb      a5, 2(a4)
 srli    a2, a2, 8
 sb      a2, 1(a4)
 addi    a3, a3, -8
 addi    a6, a6, 8
 bltu    t0, a3, .LBB8_10
.LBB8_11:
 beqz    a3, .LBB8_14
 addi    a2, sp, 8
 add     a4, a2, a6
 add     a1, a1, a6
.LBB8_13:
 lb      a2, 0(a1)
 sb      a2, 0(a4)
 addi    a3, a3, -1
 addi    a4, a4, 1
 addi    a1, a1, 1
 bnez    a3, .LBB8_13
.LBB8_14:
 addi    a1, sp, 8
 li      a2, 64
 call    memcpy@plt
 fence   r, rw
 ld      ra, 72(sp)
 addi    sp, sp, 80
 ret
asm_test::atomic_memcpy_load_align4::read_volatile_acquire_fence:
 addi    sp, sp, -16
 sd      s0, 8(sp)
 sd      s1, 0(sp)
 lw      a6, 60(a1)
 lw      a7, 56(a1)
 lw      t0, 52(a1)
 lw      t1, 48(a1)
 lw      t2, 44(a1)
 lw      t3, 40(a1)
 lw      t4, 36(a1)
 lw      t5, 32(a1)
 lw      t6, 28(a1)
 lw      a3, 24(a1)
 lw      a4, 20(a1)
 lw      a5, 16(a1)
 lw      a2, 12(a1)
 lw      s0, 8(a1)
 lw      s1, 4(a1)
 lw      a1, 0(a1)
 sw      a1, 0(a0)
 sw      s1, 4(a0)
 sw      s0, 8(a0)
 sw      a2, 12(a0)
 sw      a5, 16(a0)
 sw      a4, 20(a0)
 sw      a3, 24(a0)
 sw      t6, 28(a0)
 sw      t5, 32(a0)
 sw      t4, 36(a0)
 sw      t3, 40(a0)
 sw      t2, 44(a0)
 sw      t1, 48(a0)
 sw      t0, 52(a0)
 sw      a7, 56(a0)
 sw      a6, 60(a0)
 fence   r, rw
 ld      s0, 8(sp)
 ld      s1, 0(sp)
 addi    sp, sp, 16
 ret
