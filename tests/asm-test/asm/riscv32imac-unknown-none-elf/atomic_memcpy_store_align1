asm_test::atomic_memcpy_store_align1::release:
 lbu     a2, 29(a1)
 lbu     a3, 28(a1)
 lbu     a4, 31(a1)
 lbu     a5, 30(a1)
 slli    a2, a2, 8
 or      a2, a2, a3
 slli    a3, a4, 8
 or      a3, a3, a5
 slli    a3, a3, 16
 or      a2, a2, a3
 sw      a2, 28(sp)
 lbu     a2, 25(a1)
 lbu     a3, 24(a1)
 lbu     a4, 27(a1)
 lbu     a5, 26(a1)
 slli    a2, a2, 8
 or      a2, a2, a3
 slli    a3, a4, 8
 or      a3, a3, a5
 slli    a3, a3, 16
 or      a2, a2, a3
 sw      a2, 24(sp)
 lbu     a2, 21(a1)
 lbu     a3, 20(a1)
 lbu     a4, 23(a1)
 lbu     a5, 22(a1)
 slli    a2, a2, 8
 or      a2, a2, a3
 slli    a3, a4, 8
 or      a3, a3, a5
 slli    a3, a3, 16
 or      a2, a2, a3
 sw      a2, 20(sp)
 lbu     a2, 17(a1)
 lbu     a3, 16(a1)
 lbu     a4, 19(a1)
 lbu     a5, 18(a1)
 slli    a2, a2, 8
 or      a2, a2, a3
 slli    a3, a4, 8
 or      a3, a3, a5
 slli    a3, a3, 16
 or      a2, a2, a3
 sw      a2, 16(sp)
 lbu     a2, 13(a1)
 lbu     a3, 12(a1)
 lbu     a4, 15(a1)
 lbu     a5, 14(a1)
 slli    a2, a2, 8
 or      a2, a2, a3
 slli    a3, a4, 8
 or      a3, a3, a5
 slli    a3, a3, 16
 or      a2, a2, a3
 sw      a2, 12(sp)
 lbu     a2, 9(a1)
 lbu     a3, 8(a1)
 lbu     a4, 11(a1)
 lbu     a5, 10(a1)
 slli    a2, a2, 8
 or      a2, a2, a3
 slli    a3, a4, 8
 or      a3, a3, a5
 slli    a3, a3, 16
 or      a2, a2, a3
 sw      a2, 8(sp)
 lbu     a2, 5(a1)
 lbu     a3, 4(a1)
 lbu     a4, 7(a1)
 lbu     a5, 6(a1)
 slli    a2, a2, 8
 or      a2, a2, a3
 slli    a3, a4, 8
 or      a3, a3, a5
 slli    a3, a3, 16
 or      a2, a2, a3
 sw      a2, 4(sp)
 lbu     a2, 1(a1)
 lbu     a3, 0(a1)
 lbu     a4, 3(a1)
 lbu     a1, 2(a1)
 slli    a2, a2, 8
 or      a2, a2, a3
 slli    a3, a4, 8
 or      a1, a1, a3
 slli    a1, a1, 16
 or      a1, a1, a2
 sw      a1, 0(sp)
 fence   rw, w
 lw      a1, 28(sp)
 lw      a2, 24(sp)
 lw      a3, 20(sp)
 sw      a1, 60(sp)
 sw      a2, 56(sp)
 sw      a3, 52(sp)
 lw      a1, 16(sp)
 lw      a2, 12(sp)
 lw      a3, 8(sp)
 lw      a4, 4(sp)
 sw      a1, 48(sp)
 sw      a2, 44(sp)
 sw      a3, 40(sp)
 sw      a4, 36(sp)
 lw      a3, 0(sp)
 addi    a1, a0, 3
 andi    a6, a1, -4
 sub     a1, a6, a0
 addi    a4, zero, 33
 sw      a3, 32(sp)
 bltu    a1, a4, .LBB2_2
 lb      a1, 32(sp)
 sb      a1, 0(a0)
 lb      a1, 33(sp)
 sb      a1, 1(a0)
 lb      a1, 34(sp)
 sb      a1, 2(a0)
 lb      a1, 35(sp)
 sb      a1, 3(a0)
 lb      a1, 36(sp)
 sb      a1, 4(a0)
 lb      a1, 37(sp)
 sb      a1, 5(a0)
 lb      a1, 38(sp)
 sb      a1, 6(a0)
 lb      a1, 39(sp)
 sb      a1, 7(a0)
 lb      a1, 40(sp)
 sb      a1, 8(a0)
 lb      a1, 41(sp)
 sb      a1, 9(a0)
 lb      a1, 42(sp)
 sb      a1, 10(a0)
 lb      a1, 43(sp)
 sb      a1, 11(a0)
 lb      a1, 44(sp)
 sb      a1, 12(a0)
 lb      a1, 45(sp)
 sb      a1, 13(a0)
 lb      a1, 46(sp)
 sb      a1, 14(a0)
 lb      a1, 47(sp)
 sb      a1, 15(a0)
 lb      a1, 48(sp)
 sb      a1, 16(a0)
 lb      a1, 49(sp)
 sb      a1, 17(a0)
 lb      a1, 50(sp)
 sb      a1, 18(a0)
 lb      a1, 51(sp)
 sb      a1, 19(a0)
 lb      a1, 52(sp)
 sb      a1, 20(a0)
 lb      a1, 53(sp)
 sb      a1, 21(a0)
 lb      a1, 54(sp)
 sb      a1, 22(a0)
 lb      a1, 55(sp)
 sb      a1, 23(a0)
 lb      a1, 56(sp)
 sb      a1, 24(a0)
 lb      a1, 57(sp)
 sb      a1, 25(a0)
 lb      a1, 58(sp)
 sb      a1, 26(a0)
 lb      a1, 59(sp)
 sb      a1, 27(a0)
 lb      a1, 60(sp)
 sb      a1, 28(a0)
 lb      a1, 61(sp)
 sb      a1, 29(a0)
 lb      a1, 62(sp)
 sb      a1, 30(a0)
 lb      a1, 63(sp)
 sb      a1, 31(a0)
 addi    sp, sp, 64
 ret
.LBB2_2:
 beqz    a1, .LBB2_6
 sub     a4, a0, a6
 addi    a3, sp, 32
 mv      a5, a0
.LBB2_4:
 lb      a7, 0(a3)
 mv      a2, a4
 sb      a7, 0(a5)
 addi    a5, a5, 1
 addi    a4, a4, 1
 addi    a3, a3, 1
 bgeu    a4, a2, .LBB2_4
 sub     a2, a0, a6
 addi    a2, a2, 32
 addi    a3, zero, 4
 bgeu    a2, a3, .LBB2_7
 j       .LBB2_9
.LBB2_6:
 addi    a2, zero, 32
.LBB2_7:
 addi    a6, sp, 32
 addi    a7, zero, 3
.LBB2_8:
 add     a5, a6, a1
 lbu     t0, 1(a5)
 lbu     t1, 0(a5)
 lbu     a3, 3(a5)
 lbu     a5, 2(a5)
 slli    a4, t0, 8
 or      a4, a4, t1
 slli    a3, a3, 8
 or      a3, a3, a5
 slli    a3, a3, 16
 or      a3, a3, a4
 add     a4, a0, a1
 sw      a3, 0(a4)
 addi    a2, a2, -4
 addi    a1, a1, 4
 bltu    a7, a2, .LBB2_8
.LBB2_9:
 beqz    a2, .LBB2_12
 add     a0, a0, a1
 addi    a3, sp, 32
 add     a1, a1, a3
.LBB2_11:
 lb      a3, 0(a1)
 sb      a3, 0(a0)
 addi    a0, a0, 1
 addi    a2, a2, -1
 addi    a1, a1, 1
 bnez    a2, .LBB2_11
.LBB2_12:
 addi    sp, sp, 64
 ret
.LBB4_2:
 lw      a2, 0(a1)
 sw      a2, 12(sp)
 lw      a2, 4(a1)
 sw      a2, 16(sp)
 lw      a2, 8(a1)
 sw      a2, 20(sp)
 lw      a2, 12(a1)
 sw      a2, 24(sp)
 lw      a2, 16(a1)
 sw      a2, 28(sp)
 lw      a2, 20(a1)
 sw      a2, 32(sp)
 lw      a2, 24(a1)
 sw      a2, 36(sp)
 lw      a1, 28(a1)
 sw      a1, 40(sp)
.LBB4_3:
 addi    a1, sp, 12
 addi    a2, zero, 32
 call    memcpy@plt
 fence   r, rw
 lw      ra, 44(sp)
 addi    sp, sp, 48
 ret
.LBB6_2:
 lw      a1, 32(sp)
 sw      a1, 0(a0)
 lw      a1, 36(sp)
 sw      a1, 4(a0)
 lw      a1, 40(sp)
 sw      a1, 8(a0)
 lw      a1, 44(sp)
 sw      a1, 12(a0)
 lw      a1, 48(sp)
 sw      a1, 16(a0)
 lw      a1, 52(sp)
 sw      a1, 20(a0)
 lw      a1, 56(sp)
 sw      a1, 24(a0)
 lw      a1, 60(sp)
 sw      a1, 28(a0)
 addi    sp, sp, 64
 ret
asm_test::atomic_memcpy_store_align1::write_volatile_release_fence:
 sw      ra, 44(sp)
 fence   rw, w
 lbu     a2, 29(a1)
 lbu     a3, 28(a1)
 lbu     a4, 31(a1)
 lbu     a5, 30(a1)
 slli    a2, a2, 8
 or      a2, a2, a3
 slli    a3, a4, 8
 or      a3, a3, a5
 slli    a3, a3, 16
 or      a2, a2, a3
 sw      a2, 40(sp)
 lbu     a2, 25(a1)
 lbu     a3, 24(a1)
 lbu     a4, 27(a1)
 lbu     a5, 26(a1)
 slli    a2, a2, 8
 or      a2, a2, a3
 slli    a3, a4, 8
 or      a3, a3, a5
 slli    a3, a3, 16
 or      a2, a2, a3
 sw      a2, 36(sp)
 lbu     a2, 21(a1)
 lbu     a3, 20(a1)
 lbu     a4, 23(a1)
 lbu     a5, 22(a1)
 slli    a2, a2, 8
 or      a2, a2, a3
 slli    a3, a4, 8
 or      a3, a3, a5
 slli    a3, a3, 16
 or      a2, a2, a3
 sw      a2, 32(sp)
 lbu     a2, 17(a1)
 lbu     a3, 16(a1)
 lbu     a4, 19(a1)
 lbu     a5, 18(a1)
 slli    a2, a2, 8
 or      a2, a2, a3
 slli    a3, a4, 8
 or      a3, a3, a5
 slli    a3, a3, 16
 or      a2, a2, a3
 sw      a2, 28(sp)
 lbu     a2, 13(a1)
 lbu     a3, 12(a1)
 lbu     a4, 15(a1)
 lbu     a5, 14(a1)
 slli    a2, a2, 8
 or      a2, a2, a3
 slli    a3, a4, 8
 or      a3, a3, a5
 slli    a3, a3, 16
 or      a2, a2, a3
 sw      a2, 24(sp)
 lbu     a2, 9(a1)
 lbu     a3, 8(a1)
 lbu     a4, 11(a1)
 lbu     a5, 10(a1)
 slli    a2, a2, 8
 or      a2, a2, a3
 slli    a3, a4, 8
 or      a3, a3, a5
 slli    a3, a3, 16
 or      a2, a2, a3
 sw      a2, 20(sp)
 lbu     a2, 5(a1)
 lbu     a3, 4(a1)
 lbu     a4, 7(a1)
 lbu     a5, 6(a1)
 slli    a2, a2, 8
 or      a2, a2, a3
 slli    a3, a4, 8
 or      a3, a3, a5
 slli    a3, a3, 16
 or      a2, a2, a3
 sw      a2, 16(sp)
 lbu     a2, 1(a1)
 lbu     a3, 0(a1)
 lbu     a4, 3(a1)
 lbu     a1, 2(a1)
 slli    a2, a2, 8
 or      a2, a2, a3
 slli    a3, a4, 8
 or      a1, a1, a3
 slli    a1, a1, 16
 or      a1, a1, a2
 sw      a1, 12(sp)
 addi    a1, sp, 12
 addi    a2, zero, 32
 call    memcpy@plt
 lw      ra, 44(sp)
 addi    sp, sp, 48
 ret
.LBB4_2:
 lw      a2, 0(a1)
 sw      a2, 12(sp)
 lw      a2, 4(a1)
 sw      a2, 16(sp)
 lw      a2, 8(a1)
 sw      a2, 20(sp)
 lw      a2, 12(a1)
 sw      a2, 24(sp)
 lw      a2, 16(a1)
 sw      a2, 28(sp)
 lw      a2, 20(a1)
 sw      a2, 32(sp)
 lw      a2, 24(a1)
 sw      a2, 36(sp)
 lw      a1, 28(a1)
 sw      a1, 40(sp)
.LBB4_3:
 addi    a1, sp, 12
 addi    a2, zero, 32
 call    memcpy@plt
 fence   r, rw
 lw      ra, 44(sp)
 addi    sp, sp, 48
 ret
.LBB6_2:
 lw      a1, 32(sp)
 sw      a1, 0(a0)
 lw      a1, 36(sp)
 sw      a1, 4(a0)
 lw      a1, 40(sp)
 sw      a1, 8(a0)
 lw      a1, 44(sp)
 sw      a1, 12(a0)
 lw      a1, 48(sp)
 sw      a1, 16(a0)
 lw      a1, 52(sp)
 sw      a1, 20(a0)
 lw      a1, 56(sp)
 sw      a1, 24(a0)
 lw      a1, 60(sp)
 sw      a1, 28(a0)
 addi    sp, sp, 64
 ret
